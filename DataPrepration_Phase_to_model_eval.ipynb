{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_uk75BK63OyFSuExv2fq7VgKjeRFMIEi",
      "authorship_tag": "ABX9TyMg6dgrOficPeotTx5c0aoS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Geetanshi-jain/DSAssignmentByGeetanshijain/blob/main/DataPrepration_Phase_to_model_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnm3_QhaxBTO",
        "outputId": "9fa97c9d-da80-451d-bc94-1ccc16792b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset shape: (10, 13)\n",
            "Training dataset shape: (7, 13)\n",
            "Testing dataset shape: (3, 13)\n"
          ]
        }
      ],
      "source": [
        "# DATA PREPARATION PHASE TO MODEL THE DATA\n",
        "#How to Partition the Data Python -\n",
        "# pandas - data manipulation\n",
        "# sklearn - train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "## Read in the bank_additional data set\n",
        "bank = pd.read_csv(\"bank-additional.csv\")\n",
        "#Partitioning the Dataset\n",
        "#To partition the dataset into training and test sets, we will use the train_test_split()\n",
        "#function. This command creates two new datasets: bank_train and bank_test.\n",
        "# Partition the data set\n",
        "bank_train, bank_test = train_test_split(bank, test_size=0.25, random_state=7)\n",
        "\n",
        "\"\"\"bank: This is the original dataset we are partitioning.\n",
        "test_size=0.25: This parameter indicates that 25% of the data should be allocated\n",
        " to the test set. Consequently, 75% will be used for training.\n",
        "random_state=7: This parameter sets a seed for the random number generator,\n",
        "ensuring that the split is reproducible. By using the same seed,\n",
        "you will always get the same result when you run the code again.\"\"\"\n",
        "# Check the shapes of the datasets\n",
        "print(\"Original dataset shape:\", bank.shape)\n",
        "print(\"Training dataset shape:\", bank_train.shape)\n",
        "print(\"Testing dataset shape:\", bank_test.shape)\n",
        "#For example, if the original dataset has 1000 rows, the expected outputs should be:\n",
        "\n",
        "#bank.shape → (1000, x) (where x is the number of columns)\n",
        "#bank_train.shape → (750, x)\n",
        "#bank_test.shape → (250, x)\n",
        "#This confirms that:\n",
        "\n",
        "#750 + 250 = 1000 (total records)\n",
        "#250 is 25% of 1000\n"
      ]
    }
  ]
}